---
title: "Descriptives"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Loading final data set from Targets cache

```{r loading data}
d <- targets::tar_read(data_context)
```

## Variables used in the analysis

### Tweet level

* status_id
* user_id
* created_at
* dl_at: time of download of tweet in UTC time
* text: text as returned by the Twitter API
* text_clean: text without links, tags, line breaks, punctuation, "&amp" encoding and redundant white space
* is_retweet
* is_quote
* favorite_count
* retweet_count
* lang: only languages that were recognized as English by Twitter's AI were included in final data set
* nchar: number of character of text_clean
* nwords: number of word of text_clean

### Context variables

* isChat: 1 if tweet was posted inside of #NGSSchat chat session, 0 if not, NA if tweet does not include #NGSSchat
* q: variable with the levels "#NGSSchat", "ngss" and "other" representing if the tweet includes #NGSSchat, the term ngss (and not #NGSSchat) or any other NGSS-related search term (and not the two aformentioned terms)

### Sentiment variables (by class; featuring SentiStrength, LIWC, Tidytext)

* {method}_pos: Positivity rating of tweet. Standardized by number of words for Tidytext rating and truncated to 4 for SentiStrength rating.
* {method}_neg: Negativity rating of tweet. Standardized by number of words for Tidytext rating and truncated to 4 for SentiStrength rating.
* {method}_scale: Positivity + Negativity rating (if negativity score is { 0, else minus)
* {method}_{pos/neg/scale}_scaled: base::scale() applied to individiual ratings
* {method}_binary: Binary (pos/neg) rating of tweets by method for validation. SentiStrength's binary method was employed and for LIWC and Tidytext, a positive classification was assigned if the respective scale was }= 0.

* {method}_ambi: Ambiguity control measure defined as the sum of the absolute differences from 0 for each method's positivity and negativity ratings

* {method}_{method}_discrepancy_{pos/neg/scale}: Squared difference between base::scaled() ratings (positivity, negativity, scale) for all three pairs of methods. NaN if no comparison was possible due to NAs
* total_discrepancy_{pos/neg/scale}: Sum of pair-wise discrepancies for all three ratings (positivity, negativity, scale), dividied by the number of available comparisons.
* n_combinations_{pos/neg/scale}: Number of available comparisons for total_discrepancy_{pos/neg/scale} for later reference. Currently this index is equally large for pos/neg/scale alike, as 0s were assigned in tidytext dictionary approaches when at least one match (positive or negative) was found. CB: We might want to re-discuss this, it seems to alter results quite a bit.

## Correlations pos scales

```{r correlations scales pos}
d %>%
  filter_all(any_vars(!is.na(.))) %>% 
  select(ends_with("pos")) %>% 
  select_if(is.numeric) %>% 
  corrr::correlate() %>% 
  corrr::fashion() %>%
  knitr::kable()
```

## Correlations neg scales

```{r correlations scales neg}
d %>% 
  filter_all(any_vars(!is.na(.))) %>% 
  select(ends_with("neg")) %>% 
  select_if(is.numeric) %>% 
  corrr::correlate() %>% 
  corrr::fashion() %>%
  knitr::kable()
```

## Correlations overall scales

```{r correlations scales overall}
d %>% 
  filter_all(any_vars(!is.na(.))) %>% 
  select(ends_with("scale")) %>% 
  select_if(is.numeric) %>% 
  corrr::correlate() %>% 
  corrr::fashion() %>%
  knitr::kable()
```

## Correlations ambiguity measures

```{r correlations ambiguity measures}
d %>% 
  filter_all(any_vars(!is.na(.))) %>% 
  select(ends_with("ambi")) %>% 
  select_if(is.numeric) %>% 
  corrr::correlate() %>% 
  corrr::fashion() %>%
  knitr::kable()
```

## Coverage

```{r dictionary coverage, echo=FALSE}

  print("SentiStrength:")
  print((d %>% filter(ss_pos!=1 | ss_neg!=-1) %>% nrow() * 100 / nrow(d)) %>% round(2))

  print("LIWC:")
  print((d %>% filter(liwc_pos!=0 | liwc_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  
  print("Tidytext:")
  print("bing")
  print((d %>% filter(bing_pos!=0 | bing_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  print("afinn")
  print((d %>% filter(afinn_pos!=0 | afinn_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  print("loughran")
  print((d %>% filter(loughran_pos!=0 | loughran_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  print("nrc")
  print((d %>% filter(nrc_pos!=0 | nrc_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  print("tidytext overall")
  print((d %>% filter(tidytext_pos!=0 | tidytext_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))
  
  print("VADER:")
  print((d %>% filter(vader_pos!=0 | vader_neg!=0) %>% nrow() * 100 / nrow(d)) %>% round(2))

  print("All together:")
  print((d %>% 
           filter(ss_pos!=1 | ss_neg!=-1 | liwc_pos!=0 | liwc_neg!=0 | vader_pos!=0 | vader_neg!=0 | 
                    tidytext_pos!=0 | tidytext_neg!=0) %>% 
           nrow() * 100 / nrow(d)) %>% round(2))

  
```

## Pair-wise discrepancies

```{r}
d <- targets::tar_read(C_discrepancy)
d %>% 
  select(matches("disc")) %>% 
  colMeans() %>% sort() %>% as.data.frame() %>%
  knitr::kable(digits = 2)
```

## Discrepancy by context

```{r discrepancy by context}
d %>% select(
  "total_discrepancy_pos",
  "total_discrepancy_neg",
  "total_discrepancy_scale",
  "q",
  ) %>% 
  group_by(q) %>%
  summarise_all(mean) %>%
  knitr::kable(digits = 2)
```

## Discrepancy by isChat

```{r discrepancy by isChat}
d %>% select(
  "total_discrepancy_pos",
  "total_discrepancy_neg",
  "total_discrepancy_scale",
  "isChat",
  ) %>% 
  group_by(isChat) %>%
  summarise_all(mean) %>%
  knitr::kable(digits = 2)
```

## Sentiment Ratio (SentiStrenght, as in AERA open paper) by context

```{r}
d %>% select(
  "ss_binary",
  "q"
  ) %>% 
  group_by(q, ss_binary) %>%
  count() %>%
  ungroup() %>%
  spread(ss_binary, n) %>%
  mutate(Sentiment_Ratio = `1`/`-1`) %>%
  knitr::kable(digits = 2)
```

## Sentiment Ratio (SentiStrenght, as in AERA open paper) by by isChat

```{r}
d %>% select(
  "ss_binary",
  "isChat"
  ) %>% 
  group_by(isChat, ss_binary) %>%
  count() %>%
  ungroup() %>%
  spread(ss_binary, n) %>%
  mutate(Sentiment_Ratio = `1`/`-1`) %>%
  knitr::kable(digits = 2)
```

## Ambiguity by context

```{r ambiguity by context}
d %>% 
  mutate(vader_ambi=abs(vader_pos)+abs(vader_neg)) %>% 
  select(
  "ss_ambi",
  "liwc_ambi",
  "tidytext_ambi",
  "vader_ambi",
  "q",
  ) %>% 
  group_by(q) %>%
  summarise_all(mean, na.rm=T) %>%
  knitr::kable(digits = 5)
```

## Ambiguity by isChat

```{r ambiguity by isChat}
d %>% 
  mutate(vader_ambi=abs(vader_pos)+abs(vader_neg)) %>% 
  select(
  "ss_ambi",
  "liwc_ambi",
  "tidytext_ambi",
  "vader_ambi",
  "isChat",
  ) %>% 
  group_by(isChat) %>%
  summarise_all(mean, na.rm=T) %>%
  knitr::kable(digits = 5)
```

## Correlations discrepancy 

```{r correlations discrepancy}
d %>% 
  mutate(vader_ambi=abs(vader_pos)+abs(vader_neg)) %>% 
  select(nchar, nwords,
         favorite_count, retweet_count,
         ss_ambi, liwc_ambi, tidytext_ambi, vader_ambi,
         total_discrepancy_pos, total_discrepancy_neg, total_discrepancy_scale
         ) %>% 
  select_if(is.numeric) %>% 
  corrr::correlate() %>% 
  select(rowname, total_discrepancy_pos, total_discrepancy_neg, total_discrepancy_scale) %>%
  corrr::fashion() %>%
  knitr::kable()
```

